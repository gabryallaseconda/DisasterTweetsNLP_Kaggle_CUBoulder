# Disaster Tweets classification using TensorFlow

Kaggle Playground Competition ([Link](https://www.kaggle.com/competitions/nlp-getting-started))

Project for Deep Learning at CU Boulder

The data preprocessing for the text classification project surpassed standard practices, incorporating an extensive process. 
The chosen model architecture for text embedding was DistillBERT.
I used a pre-trained [model](https://www.kaggle.com/models/google/nnlm/frameworks/tensorFlow2/variations/en-dim50/versions/1?tfhub-redirect=true).

The code is organized as follows:
- Exploration.ipynb contains some analysis on training data
- Training.ipynb contains the preprocessing, training and the inference procedures.
- submission.ipynb (will not run) contains cells of the other two notebooks.